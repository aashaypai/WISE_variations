{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed73a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "#from astropy.units import cds\n",
    "#cds.enable()\n",
    "\n",
    "\n",
    "from astropy.io.ascii import masked\n",
    "from astropy.table import Table\n",
    "from astropy.timeseries import TimeSeries\n",
    "import astropy.table as at\n",
    "\n",
    "from astropy.timeseries import aggregate_downsample\n",
    "\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import kcorrect.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b5f4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILEPATH = 'C:/Users/paiaa/Documents/Research/Blanton Lab/WISE variations/'\n",
    "IMPORT_FILEPATH = 'C:/Users/paiaa/Documents/Research/Blanton Lab/WISE variations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "921aeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_manga():\n",
    "    manga_file = fits.open(IMPORT_FILEPATH + \"mnsa-0.3.0.fits\")\n",
    "    hdu_manga = manga_file[2]\n",
    "    manga_data = hdu_manga.data\n",
    "    return manga_data\n",
    "\n",
    "def write_query_table():\n",
    "    manga_file = fits.open(IMPORT_FILEPATH + \"mnsa-0.3.0.fits\")\n",
    "    RA = manga_file[1].data['objra']\n",
    "    dec = manga_file[1].data['objdec']\n",
    "    \n",
    "    table = Table([RA, dec], names=('ra', 'dec'))\n",
    "    table.write('objects_all.tbl', format = 'ipac', overwrite = True)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f5324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96483bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(ts):\n",
    "    ts = ts[ts['qual_frame'] > 0]\n",
    "    ts = ts[ts['cc_flags'] == '0000']\n",
    "    ts = ts[ts['sigra'] < 1]\n",
    "    ts = ts[ts['sigdec'] < 1]\n",
    "    \n",
    "    mask = ((ts['w1mpro'] == 'null') | (ts['w2mpro'] == 'null') | (ts['w1sigmpro'] == 'null') | (ts['w2sigmpro'] == 'null'))\n",
    "    ts = ts[~mask]\n",
    "    return ts\n",
    "\n",
    "def change_dtype(ts):\n",
    "    ts['w2mpro'] = ts['w2mpro'].astype(float)\n",
    "    ts['w1mpro'] = ts['w1mpro'].astype(float)\n",
    "    ts['w2sigmpro'] = ts['w2sigmpro'].astype(float)\n",
    "    ts['w1sigmpro'] = ts['w1sigmpro'].astype(float)\n",
    "    return ts\n",
    "\n",
    "def vega2ab(ts):\n",
    "    rd = kcorrect.response.ResponseDict()\n",
    "    rd.load_response('wise_w2')\n",
    "    ts['w2mpro'] = ts['w2mpro'] + rd['wise_w2'].vega2ab\n",
    "    \n",
    "    rd.load_response('wise_w1')\n",
    "    ts['w1mpro'] = ts['w1mpro'] + rd['wise_w1'].vega2ab\n",
    "    \n",
    "    return ts\n",
    "    \n",
    "def bin_data(ts, freq, index):\n",
    "    ts = ts[ts['cntr_01'] == index]\n",
    "    binned_ts = aggregate_downsample(ts, time_bin_size = freq * u.day, n_bins=26, aggregate_func=np.size)\n",
    "    binned_ts_avg = aggregate_downsample(ts, time_bin_size = freq * u.day, n_bins=26, aggregate_func=np.nanmean)\n",
    "    binned_ts_var = aggregate_downsample(ts, time_bin_size = freq * u.day, n_bins=26, aggregate_func=np.nanvar)\n",
    "    \n",
    "    return binned_ts, binned_ts_avg, binned_ts_var, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb0520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(ts):\n",
    "    ts = filter_data(ts)\n",
    "    ts.keep_columns(['time', 'cntr_01', 'w2mpro', 'w2sigmpro', 'w1mpro', 'w1sigmpro'])\n",
    "    ts.sort(['cntr_01', 'time'])\n",
    "    ts = change_dtype(ts)\n",
    "    ts = vega2ab(ts)\n",
    "    \n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a6c62e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: OverflowError converting to IntType in column allwise_cntr, reverting to String. [astropy.io.ascii.fastbasic]\n"
     ]
    }
   ],
   "source": [
    "neowise_data = TimeSeries.read(IMPORT_FILEPATH + 'neowise_2arcsec_catalog_search_results_all.csv', format='csv', time_column='mjd', time_format='mjd')\n",
    "allsky_data = TimeSeries.read(IMPORT_FILEPATH + 'allsky_2arcsec_catalog_search_results_all_qualframe.csv', format='csv', time_column='mjd', time_format='mjd')\n",
    "wise_data = at.vstack([neowise_data, allsky_data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c24f22",
   "metadata": {},
   "source": [
    "# Statistical Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd09ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_mag_per_epoch(ts, binned_ts, mag): \n",
    "    obs_num = binned_ts['cntr_01'].data.data\n",
    "    index = 0\n",
    "    arr = np.array([])\n",
    "\n",
    "    for i in range(obs_num.shape[0]):\n",
    "\n",
    "        temp = ts[mag].data[index:index+obs_num[i]]\n",
    "        mean = np.nansum(temp)/temp[np.isfinite(temp)].shape[0]\n",
    "        arr = np.append(arr, mean)\n",
    "        \n",
    "        index += obs_num[i]\n",
    "    return arr\n",
    "\n",
    "##FIX THIS (fixed now)\n",
    "def std_err_per_epoch(ts, binned_ts, mag, err): \n",
    "    obs_num = binned_ts['cntr_01'].data.data\n",
    "    index = 0\n",
    "    arr = np.array([])\n",
    "\n",
    "    for i in range(obs_num.shape[0]):\n",
    "        \n",
    "        temp_mag = ts[mag].data[index:index+obs_num[i]]\n",
    "        temp_err = ts[err].data[index:index+obs_num[i]]\n",
    "        \n",
    "        if (temp_mag[np.isfinite(temp_mag)]).shape[0] != 1:\n",
    "            std_err = np.nanstd(temp_mag, ddof=1)#/np.sqrt(temp_mag[np.isfinite(temp_mag)].shape[0]-1)\n",
    "\n",
    "            arr = np.append(arr, std_err)\n",
    "            \n",
    "        else:\n",
    "            #print('w2mpro:', temp_mag)\n",
    "            #print('w2sigmpro:', temp_err, 'nonzero indices:', np.nonzero(temp_err))\n",
    "            std_err = temp_err[np.nonzero(temp_err)[0]]\n",
    "            arr = np.append(arr, std_err)\n",
    "        \n",
    "        index += obs_num[i]\n",
    "    #print('std_err:', arr)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def expected_var_per_epoch_sigma(ts, binned_ts, err): \n",
    "    obs_num = binned_ts['cntr_01'].data.data\n",
    "    index = 0\n",
    "    arr = np.array([])\n",
    "    for i in range(obs_num.shape[0]):\n",
    "\n",
    "        temp = ts[err].data[index:index+obs_num[i]]\n",
    "        var = np.nansum(np.square(temp))/(temp[np.isfinite(temp)].shape[0])\n",
    "        arr = np.append(arr, var)\n",
    "        \n",
    "        index += obs_num[i]\n",
    "    return arr\n",
    "\n",
    "\n",
    "def expected_var_per_epoch_mags(ts, binned_ts, mag): \n",
    "    obs_num = binned_ts['cntr_01'].data.data\n",
    "    index = 0\n",
    "    arr = np.array([])\n",
    "    for i in range(obs_num.shape[0]):\n",
    "        \n",
    "        temp = ts[mag].data[index:index+obs_num[i]]\n",
    "        var = np.nanvar(temp, ddof=1)\n",
    "        arr = np.append(arr, var)\n",
    "        \n",
    "        index += obs_num[i]\n",
    "    #print('var:', arr)\n",
    "    return arr\n",
    "\n",
    "def expected_var_per_epoch_mags_mean(ts, binned_ts, mag): \n",
    "    obs_num = binned_ts['cntr_01'].data.data\n",
    "    index = 0\n",
    "    arr = np.array([])\n",
    "    for i in range(obs_num.shape[0]):\n",
    "\n",
    "        temp = ts[mag].data[index:index+obs_num[i]]\n",
    "        var = np.nanvar(temp, ddof=1)/(temp[np.isfinite(temp)].shape[0])\n",
    "        arr = np.append(arr, var)\n",
    "        \n",
    "        index += obs_num[i]\n",
    "    return arr\n",
    "\n",
    "def expected_var_per_epoch_sigma_mean(ts, binned_ts, err): \n",
    "    obs_num = binned_ts['cntr_01'].data.data\n",
    "    index = 0\n",
    "    arr = np.array([])\n",
    "    for i in range(obs_num.shape[0]):\n",
    "\n",
    "        temp = ts[err].data[index:index+obs_num[i]]\n",
    "        var = np.nansum(np.square(temp))/np.square(temp[np.isfinite(temp)].shape[0])\n",
    "        arr = np.append(arr, var)\n",
    "        \n",
    "        index += obs_num[i]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f79fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_var_all(ts, binned_ts_avg, mag):\n",
    "    \n",
    "    var = np.nanvar(binned_ts_avg[mag], ddof=1)\n",
    "    \n",
    "    return var\n",
    "\n",
    "def expected_var_all_sigma(ts, binned_ts, err):\n",
    "    per_epoch_var = expected_var_per_epoch_sigma_mean(ts, binned_ts, err)\n",
    "    \n",
    "    var = np.nanmean(per_epoch_var)\n",
    "    \n",
    "    return var\n",
    "\n",
    "def expected_var_all_mags(ts, binned_ts, mag):\n",
    "    per_epoch_var = expected_var_per_epoch_mags_mean(ts, binned_ts, mag)\n",
    "    \n",
    "    var = np.nanmean(per_epoch_var)\n",
    "    \n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c85a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plateifu():\n",
    "    \n",
    "    return MANGA_DATA['plateifu']\n",
    "\n",
    "def date_per_epoch(ts, binned_ts):\n",
    "    \n",
    "    return binned_ts['time_bin_start'].value\n",
    "\n",
    "def obs_per_epoch(ts, binned_ts):\n",
    "    \n",
    "    return binned_ts['cntr_01'].data.data\n",
    "\n",
    "def epochs_per_obj(ts, binned_ts):\n",
    "    \n",
    "    return np.nonzero(binned_ts['cntr_01'])[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e3f199",
   "metadata": {},
   "source": [
    "# Creating Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a221fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(ts_full):\n",
    "    skip_counter = 0\n",
    "    pifu = plateifu()\n",
    "    index = ts_full['cntr_01'].max()+1\n",
    "\n",
    "    variability_cat = Table(names = np.array(['plateifu', 'mjd', 'obs_per_ep', 'epoch_count', 'mean_W1_per_epoch', 'mean_W2_per_epoch', 'err_W1_per_epoch', 'err_W2_per_epoch', \n",
    "                        'expected_W1_var_errs', 'expected_W2_var_errs', 'expected_W1_var_mags', 'expected_W2_var_mags', 'expected_W1_var_mean_errs', 'expected_W2_var_mean_errs', 'expected_W1_var_mean_mags', 'expected_W2_var_mean_mags', 'observed_W1_var', 'observed_W2_var',\n",
    "                     'expected_W1_var_all_errs', 'expected_W2_var_all_errs','expected_W1_var_all_mags' ,'expected_W2_var_all_mags']),\n",
    "                        dtype = np.array(['<U12', '26f8', '26i8', 'i8', '26f8', '26f8', '26f8','26f8', '26f8', '26f8','26f8', '26f8', '26f8', \n",
    "                                '26f8', '26f8', '26f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8']))\n",
    "    \n",
    "    for i in tqdm(range(1, index)):\n",
    "        #print(i)\n",
    "        ts = ts_full[ts_full['cntr_01'] == i]\n",
    "        \n",
    "        if ts['cntr_01'].size <2:\n",
    "            epochs = 26\n",
    "            w2a, w1a = np.ones(epochs)*-9999., np.ones(epochs)*-9999.\n",
    "            w2b, w1b = np.ones(epochs)*-9999., np.ones(epochs)*-9999.\n",
    "            w2c, w1c = np.ones(epochs)*-9999., np.ones(epochs)*-9999.\n",
    "            w2d, w1d = np.ones(epochs)*-9999., np.ones(epochs)*-9999.\n",
    "            w2h, w1h = np.ones(epochs)*-9999., np.ones(epochs)*-9999.\n",
    "            w2i, w1i = np.ones(epochs)*-9999., np.ones(epochs)*-9999.\n",
    "            w2e, w1e = -9999., -9999.\n",
    "            w2f, w1f = -9999., -9999.\n",
    "            w2g, w1g = -9999., -9999.\n",
    "            \n",
    "            epoch_date = np.ones(epochs)*-9999.\n",
    "            obs_per_ep = (np.ones(epochs)*-9999).astype(int)\n",
    "            ep_per_obj = int(-9999)\n",
    "            \n",
    "            variability_cat.add_row([pifu[i-1], epoch_date, obs_per_ep, ep_per_obj, w1a, w2a, w1b, w2b, w1c, w2c, w1d, w2d, w1i, w2i,\n",
    "                     w1h, w2h, w1e, w2e, w1f, w2f, w1g, w2g])\n",
    "            \n",
    "            skip_counter += 1\n",
    "            \n",
    "            #print('skipped')\n",
    "            continue\n",
    "        binned_ts, binned_ts_avg, binned_ts_var, ts = bin_data(ts, 181, int(i)) #changed freq=170 for 5.2.0\n",
    "        \n",
    "        w2a = mean_mag_per_epoch(ts, binned_ts, 'w2mpro')\n",
    "        w1a = mean_mag_per_epoch(ts, binned_ts, 'w1mpro')\n",
    "        \n",
    "        w2b = std_err_per_epoch(ts, binned_ts, 'w2mpro', 'w2sigmpro')\n",
    "        w1b = std_err_per_epoch(ts, binned_ts, 'w1mpro', 'w1sigmpro')\n",
    "        \n",
    "        w2c = expected_var_per_epoch_sigma(ts, binned_ts, 'w2sigmpro')\n",
    "        w1c = expected_var_per_epoch_sigma(ts, binned_ts, 'w1sigmpro')\n",
    "        \n",
    "        w2d = expected_var_per_epoch_mags(ts, binned_ts, 'w2mpro')\n",
    "        w1d = expected_var_per_epoch_mags(ts, binned_ts, 'w1mpro')\n",
    "        \n",
    "        w2i = expected_var_per_epoch_sigma_mean(ts, binned_ts, 'w2sigmpro')\n",
    "        w1i = expected_var_per_epoch_sigma_mean(ts, binned_ts, 'w1sigmpro')\n",
    "        \n",
    "        w2h = expected_var_per_epoch_mags_mean(ts, binned_ts, 'w2mpro')\n",
    "        w1h = expected_var_per_epoch_mags_mean(ts, binned_ts, 'w1mpro')\n",
    "        \n",
    "        w2e = obs_var_all(ts, binned_ts_avg, 'w2mpro')\n",
    "        w1e = obs_var_all(ts, binned_ts_avg, 'w1mpro')\n",
    "        \n",
    "        w2f = expected_var_all_sigma(ts, binned_ts, 'w2sigmpro')\n",
    "        w1f = expected_var_all_sigma(ts, binned_ts, 'w1sigmpro')\n",
    "        \n",
    "        w2g = expected_var_all_mags(ts, binned_ts, 'w2mpro')\n",
    "        w1g = expected_var_all_mags(ts, binned_ts, 'w1mpro')\n",
    "        \n",
    "\n",
    "        epoch_date = date_per_epoch(ts, binned_ts)\n",
    "        obs_per_ep = obs_per_epoch(ts, binned_ts)\n",
    "        ep_per_obj = epochs_per_obj(ts, binned_ts)\n",
    "        \n",
    "        variability_cat.add_row([pifu[i-1], epoch_date, obs_per_ep, ep_per_obj, w1a, w2a, w1b, w2b, w1c, w2c, w1d, w2d, w1i, w2i, \n",
    "                     w1h, w2h, w1e, w2e, w1f, w2f, w1g, w2g])\n",
    "        \n",
    "    print(skip_counter, ' objects have less than 2 observations')\n",
    "    print('**************************')\n",
    "    print('adding coordinates')\n",
    "    ra, dec = get_coords(variability_cat)\n",
    "    variability_cat.add_column(ra, name='ra', index=1)\n",
    "    variability_cat.add_column(dec, name='dec', index=2)\n",
    "    print('**************************')\n",
    "    print('creating flags')\n",
    "    viflags, epflags, varflags = create_flags(variability_cat)\n",
    "    variability_cat.add_column(viflags.astype(int), name='vi_flag')\n",
    "    variability_cat.add_column(epflags.astype(int), name='epoch_flag')\n",
    "    variability_cat.add_column(varflags.astype(int), name='var_flag')\n",
    "    print('**************************')\n",
    "\n",
    "    return variability_cat\n",
    "\n",
    "def create_flags(table):\n",
    "    \n",
    "    visual_inspection_flag = np.array([])\n",
    "    epoch_flag = np.array([])\n",
    "    var_flag = np.array([])\n",
    "    \n",
    "    for pifu in table['plateifu']:\n",
    "        if pifu in ['8132-6102', '8145-6102', '8239-3701', '8333-3703', \n",
    "                    '8445-3701', '8447-9102','8483-12701', '8616-12701', '9024-12705',\n",
    "                    '10217-3704', '10515-6102', '12078-6102', '12085-1902', '12651-3703', '12667-6104']:\n",
    "                   #'11863-3703', '9046-1902', '8133-12702', '9497-12705']: #this row doesn't have manga w1/w2\n",
    "            visual_inspection_flag = np.append(visual_inspection_flag, 1)\n",
    "        else:\n",
    "            visual_inspection_flag = np.append(visual_inspection_flag, 0)\n",
    "    \n",
    "    for pifu in table['plateifu']:\n",
    "        if pifu in table[table['epoch_count']<4]['plateifu']:\n",
    "            epoch_flag = np.append(epoch_flag, 1)\n",
    "        else:\n",
    "            epoch_flag = np.append(epoch_flag, 0)\n",
    "            \n",
    "    catalog = Table.read(IMPORT_FILEPATH+'/Final Plots/' + 'variability_catalog', format='ascii')\n",
    "    \n",
    "    for pifu in table['plateifu']:\n",
    "        if pifu in catalog['Plateifu']:\n",
    "            var_flag = np.append(var_flag, 1)\n",
    "        else:\n",
    "            var_flag = np.append(var_flag, 0)\n",
    "            \n",
    "    return visual_inspection_flag, epoch_flag, var_flag\n",
    "\n",
    "def get_coords(table):\n",
    "    manga_file = fits.open(IMPORT_FILEPATH + \"mnsa-0.3.0.fits\")\n",
    "    mf = manga_file[1].data\n",
    "    \n",
    "    ra = np.array([])\n",
    "    dec = np.array([])\n",
    "    \n",
    "    for pifu in table['plateifu']:\n",
    "        ra = np.append(ra, mf[mf['plateifu'] == pifu]['objra'])\n",
    "        dec = np.append(dec, mf[mf['plateifu'] == pifu]['objdec'])\n",
    "    \n",
    "    return ra, dec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf68919",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accf285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(wise_data, version='temp'):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    try:\n",
    "        print('processing data')\n",
    "        w_data = process_data(wise_data)\n",
    "    except:\n",
    "        print('data processing failed!')\n",
    "        return None, None\n",
    "    \n",
    "    try: \n",
    "        print('performing statistical calculations')\n",
    "        catalog = calculate_stats(w_data)\n",
    "    except:\n",
    "        print('statistical calculations failed!')\n",
    "        return w_data, None\n",
    "    \n",
    "    try:\n",
    "        print('saving catalog')\n",
    "        catalog.write(SAVE_FILEPATH + 'manga-wise-variable-'+version+'.fits', overwrite=True)\n",
    "    except:\n",
    "        print('unable to save the catalog!')\n",
    "        return catalog\n",
    "    \n",
    "\n",
    "    t2 = time.time()\n",
    "    \n",
    "    print('**************************')\n",
    "    print('total time taken:', np.round(t2-t1, 2), 'seconds')\n",
    "    return w_data, catalog\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f33fe2eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        MANGA_DATA = import_manga()\n",
    "    except:\n",
    "        print('unable to import MaNGA data!')\n",
    "    ts1, cat1 = main(wise_data, version='0.3.1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
